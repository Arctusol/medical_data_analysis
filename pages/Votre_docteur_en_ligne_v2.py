import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent
from langchain import hub
from google.cloud import bigquery
import pandas as pd
import os
from sqlalchemy.engine import create_engine
from sqlalchemy_bigquery import BigQueryDialect
import time

# Titre de la page
st.title("Votre Docteur en Ligne V2 - Assistant SQL")

try:
    # Configuration Azure OpenAI
    AZURE_CONFIG = {
        "api_version": "2023-05-15",
        "azure_endpoint": st.secrets["azure"]["AZURE_ENDPOINT"],
        "azure_deployment": st.secrets["azure"]["AZURE_DEPLOYMENT_NAME"],
        "api_key": st.secrets["azure"]["AZURE_API_KEY"]
    }

    @st.cache_resource
    def init_database():
        """Initialise la connexion √† la base de donn√©es."""
        try:
            # Chargement des secrets
            gcp_service_account = st.secrets["gcp_service_account"]
            project_id = gcp_service_account["project_id"]
            
            # Cr√©er l'URL de connexion BigQuery
            connection_string = f"bigquery://{project_id}/dbt_medical_analysis_join_total_morbidite"
            
            # Cr√©er le moteur SQLAlchemy avec les credentials
            engine = create_engine(
                connection_string,
                credentials_info=gcp_service_account
            )
            
            # Cr√©er la connexion SQLDatabase pour LangChain
            db = SQLDatabase(engine)
            
            return db
            
        except Exception as e:
            st.error(f"Erreur de connexion √† la base de donn√©es : {str(e)}")
            return None

    @st.cache_resource
    def init_agent():
        """Initialise l'agent LangChain."""
        try:
            # Initialiser le mod√®le LLM
            llm = AzureChatOpenAI(
                azure_endpoint=AZURE_CONFIG["azure_endpoint"],
                azure_deployment=AZURE_CONFIG["azure_deployment"],
                openai_api_version=AZURE_CONFIG["api_version"],
                api_key=AZURE_CONFIG["api_key"],
                temperature=0
            )
            
            # Initialiser la base de donn√©es
            db = init_database()
            if not db:
                return None
                
            # Cr√©er la bo√Æte √† outils SQL
            toolkit = SQLDatabaseToolkit(db=db, llm=llm)
            
            # Cr√©er un prompt syst√®me personnalis√© pour le contexte m√©dical
            system_message = """Vous √™tes un assistant m√©dical sp√©cialis√© dans l'analyse des donn√©es hospitali√®res fran√ßaises.
Votre r√¥le est d'aider √† comprendre et analyser les tendances en mati√®re d'hospitalisations, de pathologies et de services m√©dicaux.

Pour chaque question, vous devez :
1. Analyser soigneusement la demande de l'utilisateur
2. Cr√©er une requ√™te SQL pr√©cise et adapt√©e pour BigQuery
3. Interpr√©ter les r√©sultats de mani√®re professionnelle et accessible

R√®gles importantes :
- La table principale est `class_join_total_morbidite_population`
- Utilisez la syntaxe SQL BigQuery (par exemple DATE() pour les dates)
- Limitez les r√©sultats √† 10 lignes sauf si sp√©cifi√© autrement
- Pr√©sentez les r√©sultats de mani√®re claire avec des √©mojis appropri√©s
- Gardez un ton professionnel car nous parlons de sant√©
- Proposez des analyses compl√©mentaires pertinentes

Les colonnes principales sont :
- niveau (object) : Niveau administratif (d√©partement, r√©gion).
- cle_unique (object) : Identifiant unique par enregistrement.
- sexe (object) : Sexe (Homme/Femme/Ensemble).
- year (dbdate) : Date en format AAAA-MM-JJ.
- annee (Int64) : Ann√©e (format num√©rique).
- region (object) : Code ou nom de la r√©gion.
- code_region (Int64) : Code num√©rique de la r√©gion.
- nom_region (object) : Nom complet de la r√©gion.

Pathologie

- pathologie (object) : Code descriptif de la pathologie.
- code_pathologie (Int64) : Code num√©rique de la pathologie.
- nom_pathologie (object) : Nom complet de la pathologie.

Hospitalisations

- nbr_hospi (Int64) : Nombre total d‚Äôhospitalisations.
- evolution_nbr_hospi (Int64) : Variation absolue du nombre d‚Äôhospitalisations.
- evolution_percent_nbr_hospi (float64) : Variation en pourcentage.
- hospi_prog_24h (Int64) : Hospitalisations programm√©es (24h).
- hospi_autres_24h (Int64) : Autres hospitalisations (24h).
- hospi_total_24h (Int64) : Total hospitalisations en 24h.
- 18-29. hospi_1J √† hospi_30J (Int64) : Dur√©es d‚Äôhospitalisation (jours sp√©cifiques ou plages).
- hospi_total_jj (Int64) : Total hospitalisations, toutes dur√©es confondues.
- total_hospi (Int64) : Nombre global d‚Äôhospitalisations.
- AVG_duree_hospi (float64) : Dur√©e moyenne des hospitalisations.

√âvolution hospitali√®re

- 33-39. evolution_hospi_* (Int64, float64) : Variations absolues et en pourcentage des diff√©rents indicateurs hospitaliers (24h, total, dur√©e moyenne, etc.).
Tranches d‚Äô√¢ge

- 40-50. tranche_age_* (float64) : Proportions d‚Äôhospitalisations par tranche d‚Äô√¢ge (de 0-1 an √† 85 ans et plus).

Taux et indices

- tx_brut_tt_age_pour_mille (float64) : Taux brut pour 1 000 habitants.
- tx_standard_tt_age_pour_mille (float64) : Taux standardis√© pour 1 000 habitants.
- indice_comparatif_tt_age_percent (float64) : Indice standardis√© en pourcentage.
- 54 √† 59. evolution_tx_* (float64) : Variations de taux brut, standardis√©, et indices comparatifs en pourcentage.
Divers
- classification (object) : Classification en terme de service m√©dical : M (M√©decine), C (Chirurgie), SSR (soins de suite et de r√©adaptation), O (Obst√©trique), ESND (√âtablissement de sant√© non d√©fini), PSY (Psychoth√©rapie).
- population (Int64) : Population totale associ√©e par r√©gion et d√©partement (valeurs dupliqu√©s).
- evolution_percent_indice_comparatif_tt_age_percent (float64) : Variation en pourcentage de l'indice comparatif pour tous √¢ges.

N'h√©sitez pas √† croiser les donn√©es pour fournir des analyses pertinentes.
"""
            
            # Cr√©er l'agent SQL avec le prompt personnalis√©
            agent = create_sql_agent(
                llm=llm,
                toolkit=toolkit,
                verbose=True,
                agent_type="openai-tools",
                prefix=system_message
            )
            
            return agent
            
        except Exception as e:
            st.error(f"Erreur d'initialisation de l'agent : {str(e)}")
            return None

    def update_thinking_status(placeholder, step):
        """Met √† jour le statut de r√©flexion de l'agent."""
        thinking_states = {
            'start': "ü§î Je r√©fl√©chis √† votre question...",
            'analyzing': "üîç J'analyse les donn√©es m√©dicales pertinentes...",
            'querying': "üìä J'extrais les informations de la base de donn√©es...",
            'formatting': "‚ú® Je formule une r√©ponse claire et d√©taill√©e..."
        }
        placeholder.markdown(thinking_states.get(step, "ü§î Je r√©fl√©chis..."))
        time.sleep(1)  # Petit d√©lai pour rendre les transitions visibles

    def get_contextual_suggestions(user_input):

        templates = {
            "pathologie": ["Quelles pathologies sont les plus fr√©quentes ?", "√âvolution des hospitalisations par pathologie ?", "Comparaison des r√©gions sur les pathologies."],
            "region": ["Quelles r√©gions ont le plus d'hospitalisations ?", "Comparer les r√©gions sur le taux brut.", "Top r√©gions selon l'indice standardis√©."],
            "ann√©e": ["Tendances des hospitalisations pour l'ann√©e sp√©cifi√©e ?", "Comment le taux brut √©volue-t-il sur plusieurs ann√©es ?", "Focus sur une r√©gion pour une ann√©e sp√©cifique ?"]
        }
        
        # Analyse simple du contexte via mots-cl√©s
        context = []
        if any(word in user_input.lower() for word in ["pathologie", "maladie", "diagnostic"]):
            context.append("pathologie")
        if any(word in user_input.lower() for word in ["r√©gion", "d√©partement", "localisation"]):
            context.append("region")
        if any(word in user_input.lower() for word in ["ann√©e", "√©volution", "tendance"]):
            context.append("ann√©e")
        
        # Combine les suggestions pertinentes
        suggestions = [template for key in context for template in templates.get(key, [])]
        return suggestions if suggestions else ["Besoin d'aide pour poser une question ?"]

    def main():
        # Initialiser l'historique des messages
        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Cr√©er les containers
        chat_container = st.container()
        suggestions_container = st.container()
        input_container = st.container()

        # Afficher l'historique des messages dans le chat container
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        # G√©rer l'entr√©e utilisateur
        with input_container:
            if prompt := st.chat_input("Posez votre question sur les donn√©es m√©dicales..."):
                # Ajouter la question √† l'historique
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # Afficher la question
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # Afficher le message "en cours de r√©flexion"
                with st.chat_message("assistant"):
                    message_placeholder = st.empty()
                    
                    try:
                        # √âtape 1: D√©but de la r√©flexion
                        update_thinking_status(message_placeholder, 'start')
                        
                        # √âtape 2: Analyse de la question
                        update_thinking_status(message_placeholder, 'analyzing')
                        response = st.session_state.agent.invoke(prompt)
                        
                        # √âtape 3: Requ√™te et traitement
                        update_thinking_status(message_placeholder, 'querying')
                        final_response = response.get('output', "Je n'ai pas pu g√©n√©rer une r√©ponse.")
                        
                        # √âtape 4: Formatage de la r√©ponse
                        update_thinking_status(message_placeholder, 'formatting')
                        time.sleep(0.5)
                        
                        # Affichage de la r√©ponse finale
                        message_placeholder.markdown(final_response)
                        
                        # Ajouter la r√©ponse √† l'historique
                        st.session_state.messages.append({"role": "assistant", "content": final_response})
                        st.rerun()
                    
                    except Exception as e:
                        message_placeholder.markdown(f"‚ùå D√©sol√©, une erreur s'est produite : {str(e)}")

        # Afficher les suggestions apr√®s chaque r√©ponse
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
            with suggestions_container:
                st.markdown("### üí° Pour approfondir :")
                suggestions = get_contextual_suggestions(st.session_state.messages[-2]["content"])  # Get suggestions based on last user message
                
                # Cr√©er des colonnes pour les suggestions
                num_suggestions = len(suggestions)
                if num_suggestions > 0:
                    cols = st.columns(min(3, num_suggestions))  # Maximum 3 colonnes
                    for idx, suggestion in enumerate(suggestions):
                        col_idx = idx % min(3, num_suggestions)
                        with cols[col_idx]:
                            if st.button(suggestion, key=f"sugg_{idx}"):
                                st.session_state.messages.append({"role": "user", "content": suggestion})
                                with st.chat_message("user"):
                                    st.markdown(suggestion)
                                
                                with st.chat_message("assistant"):
                                    message_placeholder = st.empty()
                                    try:
                                        update_thinking_status(message_placeholder, 'start')
                                        update_thinking_status(message_placeholder, 'analyzing')
                                        response = st.session_state.agent.invoke(suggestion)
                                        update_thinking_status(message_placeholder, 'querying')
                                        final_response = response.get('output', "Je n'ai pas pu g√©n√©rer une r√©ponse.")
                                        update_thinking_status(message_placeholder, 'formatting')
                                        time.sleep(0.5)
                                        message_placeholder.markdown(final_response)
                                        st.session_state.messages.append({"role": "assistant", "content": final_response})
                                        st.rerun()
                                    except Exception as e:
                                        message_placeholder.markdown(f"‚ùå D√©sol√©, une erreur s'est produite : {str(e)}")

        # Bouton pour nouvelle conversation
        if st.button("üîÑ Nouvelle conversation"):
            st.session_state.messages = []
            st.rerun()

    # Initialisation uniquement si tous les imports sont disponibles
    if 'agent' not in st.session_state:
        db = init_database()
        if db is not None:
            st.session_state.agent = init_agent()

    # Interface utilisateur
    main()

except ImportError as e:
    st.error(f"Certains packages requis ne sont pas install√©s : {str(e)}")
    st.info("Assurez-vous d'avoir install√© tous les packages n√©cessaires : langchain-openai, langchain-community, sqlalchemy-bigquery")
except Exception as e:
    st.error(f"Une erreur s'est produite : {str(e)}")
