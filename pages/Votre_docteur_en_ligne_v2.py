import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits.sql.base import create_sql_agent
from langchain import hub
from google.cloud import bigquery
import pandas as pd
import os
from sqlalchemy.engine import create_engine
from sqlalchemy_bigquery import BigQueryDialect
import time

# Titre de la page
st.title("Votre Docteur en Ligne V2 - Assistant SQL")

try:
    # Configuration Azure OpenAI
    AZURE_CONFIG = {
        "api_version": "2023-05-15",
        "azure_endpoint": st.secrets["azure"]["AZURE_ENDPOINT"],
        "azure_deployment": st.secrets["azure"]["AZURE_DEPLOYMENT_NAME"],
        "api_key": st.secrets["azure"]["AZURE_API_KEY"]
    }

    @st.cache_resource
    def init_database():
        """Initialise la connexion √† la base de donn√©es."""
        try:
            # Chargement des secrets
            gcp_service_account = st.secrets["gcp_service_account"]
            project_id = gcp_service_account["project_id"]
            
            # Cr√©er l'URL de connexion BigQuery
            connection_string = f"bigquery://{project_id}/dbt_medical_analysis_join_total_morbidite"
            
            # Cr√©er le moteur SQLAlchemy avec les credentials
            engine = create_engine(
                connection_string,
                credentials_info=gcp_service_account
            )
            
            # Cr√©er la connexion SQLDatabase pour LangChain
            db = SQLDatabase(engine)
            
            return db
            
        except Exception as e:
            st.error(f"Erreur de connexion √† la base de donn√©es : {str(e)}")
            return None

    @st.cache_resource
    def init_agent():
        """Initialise l'agent LangChain."""
        try:
            # Initialiser le mod√®le LLM
            llm = AzureChatOpenAI(
                azure_endpoint=AZURE_CONFIG["azure_endpoint"],
                azure_deployment=AZURE_CONFIG["azure_deployment"],
                openai_api_version=AZURE_CONFIG["api_version"],
                api_key=AZURE_CONFIG["api_key"],
                temperature=0
            )
            
            # Initialiser la base de donn√©es
            db = init_database()
            if not db:
                return None
                
            # Cr√©er la bo√Æte √† outils SQL
            toolkit = SQLDatabaseToolkit(db=db, llm=llm)
            
            # Cr√©er un prompt syst√®me personnalis√© pour le contexte m√©dical
            system_message = """Vous √™tes un assistant m√©dical sp√©cialis√© dans l'analyse des donn√©es hospitali√®res fran√ßaises.
Votre r√¥le est d'aider √† comprendre et analyser les tendances en mati√®re d'hospitalisations, de pathologies et de services m√©dicaux.

Pour chaque question, vous devez :
1. Analyser soigneusement la demande de l'utilisateur
2. Cr√©er une requ√™te SQL pr√©cise et adapt√©e pour BigQuery
3. Interpr√©ter les r√©sultats de mani√®re professionnelle et accessible

R√®gles importantes :
- La table principale est `class_join_total_morbidite_population`
- Utilisez la syntaxe SQL BigQuery (par exemple DATE() pour les dates)
- Limitez les r√©sultats √† 10 lignes sauf si sp√©cifi√© autrement
- Pr√©sentez les r√©sultats de mani√®re claire avec des √©mojis appropri√©s
- Gardez un ton professionnel car nous parlons de sant√©
- Proposez des analyses compl√©mentaires pertinentes

Les colonnes principales sont :
- niveau (object) : Niveau administratif (d√©partement, r√©gion).
- cle_unique (object) : Identifiant unique par enregistrement.
- sexe (object) : Sexe (Homme/Femme/Ensemble).
- year (dbdate) : Date en format AAAA-MM-JJ.
- annee (Int64) : Ann√©e (format num√©rique).
- region (object) : Code ou nom de la r√©gion.
- code_region (Int64) : Code num√©rique de la r√©gion.
- nom_region (object) : Nom complet de la r√©gion.

Pathologie

- pathologie (object) : Code descriptif de la pathologie.
- code_pathologie (Int64) : Code num√©rique de la pathologie.
- nom_pathologie (object) : Nom complet de la pathologie.

Hospitalisations

- nbr_hospi (Int64) : Nombre total d‚Äôhospitalisations.
- evolution_nbr_hospi (Int64) : Variation absolue du nombre d‚Äôhospitalisations.
- evolution_percent_nbr_hospi (float64) : Variation en pourcentage.
- hospi_prog_24h (Int64) : Hospitalisations programm√©es (24h).
- hospi_autres_24h (Int64) : Autres hospitalisations (24h).
- hospi_total_24h (Int64) : Total hospitalisations en 24h.
- 18-29. hospi_1J √† hospi_30J (Int64) : Dur√©es d‚Äôhospitalisation (jours sp√©cifiques ou plages).
- hospi_total_jj (Int64) : Total hospitalisations, toutes dur√©es confondues.
- total_hospi (Int64) : Nombre global d‚Äôhospitalisations.
- AVG_duree_hospi (float64) : Dur√©e moyenne des hospitalisations.

√âvolution hospitali√®re

- 33-39. evolution_hospi_* (Int64, float64) : Variations absolues et en pourcentage des diff√©rents indicateurs hospitaliers (24h, total, dur√©e moyenne, etc.).
Tranches d‚Äô√¢ge

- 40-50. tranche_age_* (float64) : Proportions d‚Äôhospitalisations par tranche d‚Äô√¢ge (de 0-1 an √† 85 ans et plus).

Taux et indices

- tx_brut_tt_age_pour_mille (float64) : Taux brut pour 1 000 habitants.
- tx_standard_tt_age_pour_mille (float64) : Taux standardis√© pour 1 000 habitants.
- indice_comparatif_tt_age_percent (float64) : Indice standardis√© en pourcentage.
- 54 √† 59. evolution_tx_* (float64) : Variations de taux brut, standardis√©, et indices comparatifs en pourcentage.
Divers
- classification (object) : Classification en terme de service m√©dical : M (M√©decine), C (Chirurgie), SSR (soins de suite et de r√©adaptation), O (Obst√©trique), ESND (√âtablissement de sant√© non d√©fini), PSY (Psychoth√©rapie).
- population (Int64) : Population totale associ√©e par r√©gion et d√©partement (valeurs dupliqu√©s).
- evolution_percent_indice_comparatif_tt_age_percent (float64) : Variation en pourcentage de l'indice comparatif pour tous √¢ges.

N'h√©sitez pas √† croiser les donn√©es pour fournir des analyses pertinentes.
"""
            
            # Cr√©er l'agent SQL avec le prompt personnalis√©
            agent = create_sql_agent(
                llm=llm,
                toolkit=toolkit,
                verbose=True,
                agent_type="openai-tools",
                prefix=system_message
            )
            
            return agent
            
        except Exception as e:
            st.error(f"Erreur d'initialisation de l'agent : {str(e)}")
            return None

    def update_thinking_status(placeholder, step):
        """Met √† jour le statut de r√©flexion de l'agent."""
        thinking_states = {
            'start': "ü§î Je r√©fl√©chis √† votre question...",
            'analyzing': "üîç J'analyse les donn√©es m√©dicales pertinentes...",
            'querying': "üìä J'extrais les informations de la base de donn√©es...",
            'formatting': "‚ú® Je formule une r√©ponse claire et d√©taill√©e..."
        }
        placeholder.markdown(thinking_states.get(step, "ü§î Je r√©fl√©chis..."))
        time.sleep(1)  # Petit d√©lai pour rendre les transitions visibles

    def main():
        # Initialiser l'historique des messages
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        # Afficher l'historique des messages
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Zone de saisie pour la question
        if prompt := st.chat_input("Posez votre question sur les donn√©es m√©dicales..."):
            # Ajouter la question √† l'historique
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # Afficher la question
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Afficher le message "en cours de r√©flexion"
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                
                try:
                    # √âtape 1: D√©but de la r√©flexion
                    update_thinking_status(message_placeholder, 'start')
                    
                    # √âtape 2: Analyse de la question
                    update_thinking_status(message_placeholder, 'analyzing')
                    response = st.session_state.agent.invoke(prompt)
                    
                    # √âtape 3: Requ√™te et traitement
                    update_thinking_status(message_placeholder, 'querying')
                    final_response = response.get('output', "Je n'ai pas pu g√©n√©rer une r√©ponse.")
                    
                    # √âtape 4: Formatage de la r√©ponse
                    update_thinking_status(message_placeholder, 'formatting')
                    time.sleep(0.5)  # Petit d√©lai avant l'affichage final
                    
                    # Affichage de la r√©ponse finale
                    message_placeholder.markdown(final_response)
                    
                    # Ajouter la r√©ponse √† l'historique
                    st.session_state.messages.append({"role": "assistant", "content": final_response})
                    
                except Exception as e:
                    message_placeholder.markdown(f"‚ùå D√©sol√©, une erreur s'est produite : {str(e)}")

    # Initialisation uniquement si tous les imports sont disponibles
    if 'agent' not in st.session_state:
        db = init_database()
        if db is not None:
            st.session_state.agent = init_agent()

    # Interface utilisateur
    main()

except ImportError as e:
    st.error(f"Certains packages requis ne sont pas install√©s : {str(e)}")
    st.info("Assurez-vous d'avoir install√© tous les packages n√©cessaires : langchain-openai, langchain-community, sqlalchemy-bigquery")
except Exception as e:
    st.error(f"Une erreur s'est produite : {str(e)}")
